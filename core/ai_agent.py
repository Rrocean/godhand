#!/usr/bin/env python3
"""
AIAgent ğŸ¤– - è‡ªä¸»AIä»£ç†ç³»ç»Ÿ

å…·å¤‡è‡ªä¸»å†³ç­–ã€é•¿æœŸè®°å¿†ã€å¤æ‚ä»»åŠ¡è§„åˆ’çš„AI Agentã€‚
èƒ½å¤Ÿç†è§£ç”¨æˆ·æ„å›¾ï¼Œè‡ªä¸»åˆ†è§£ä»»åŠ¡ï¼Œæ‰§è¡Œå¹¶é€‚åº”ç¯å¢ƒå˜åŒ–ã€‚

Author: GodHand Team
Version: 1.0.0
"""

import json
import time
from typing import Dict, List, Optional, Any, Callable
from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum, auto
import hashlib


class AgentState(Enum):
    """ä»£ç†çŠ¶æ€"""
    IDLE = "idle"
    PLANNING = "planning"
    EXECUTING = "executing"
    REFLECTING = "reflecting"
    WAITING = "waiting"


class TaskPriority(Enum):
    """ä»»åŠ¡ä¼˜å…ˆçº§"""
    LOW = 1
    MEDIUM = 2
    HIGH = 3
    CRITICAL = 4


@dataclass
class Memory:
    """è®°å¿†å•å…ƒ"""
    content: str
    memory_type: str  # "observation", "action", "reflection", "plan"
    timestamp: float
    importance: float = 1.0
    embedding: Optional[List[float]] = None
    metadata: Dict = field(default_factory=dict)

    def to_dict(self):
        return {
            "content": self.content,
            "type": self.memory_type,
            "timestamp": self.timestamp,
            "importance": self.importance
        }


@dataclass
class Goal:
    """ç›®æ ‡"""
    id: str
    description: str
    priority: TaskPriority
    subgoals: List["Goal"] = field(default_factory=list)
    status: str = "pending"  # pending, active, completed, failed
    progress: float = 0.0
    created_at: float = field(default_factory=time.time)
    deadline: Optional[float] = None


class LongTermMemory:
    """
    é•¿æœŸè®°å¿†ç³»ç»Ÿ

    å­˜å‚¨Agentçš„è§‚å¯Ÿã€è¡ŒåŠ¨å’Œåæ€
    """

    def __init__(self, max_memories: int = 1000):
        self.memories: List[Memory] = []
        self.max_memories = max_memories
        self._memory_index: Dict[str, List[int]] = {}  # ç±»å‹ç´¢å¼•

    def add(self, memory: Memory):
        """æ·»åŠ è®°å¿†"""
        self.memories.append(memory)

        # æ›´æ–°ç´¢å¼•
        if memory.memory_type not in self._memory_index:
            self._memory_index[memory.memory_type] = []
        self._memory_index[memory.memory_type].append(len(self.memories) - 1)

        # é—å¿˜æ—§è®°å¿†
        if len(self.memories) > self.max_memories:
            self._forget_least_important()

    def _forget_least_important(self):
        """é—å¿˜æœ€ä¸é‡è¦çš„è®°å¿†"""
        if not self.memories:
            return

        # æ‰¾åˆ°é‡è¦æ€§æœ€ä½ä¸”ä¸æ˜¯åæ€çš„è®°å¿†
        min_importance = float('inf')
        min_idx = -1

        for i, mem in enumerate(self.memories):
            if mem.memory_type != "reflection" and mem.importance < min_importance:
                min_importance = mem.importance
                min_idx = i

        if min_idx >= 0:
            del self.memories[min_idx]
            self._rebuild_index()

    def _rebuild_index(self):
        """é‡å»ºç´¢å¼•"""
        self._memory_index.clear()
        for i, mem in enumerate(self.memories):
            if mem.memory_type not in self._memory_index:
                self._memory_index[mem.memory_type] = []
            self._memory_index[mem.memory_type].append(i)

    def retrieve(self, query: str, k: int = 5) -> List[Memory]:
        """æ£€ç´¢ç›¸å…³è®°å¿†"""
        # ç®€åŒ–çš„æ£€ç´¢ï¼šåŸºäºå…³é”®è¯åŒ¹é…
        # å®é™…åº”è¯¥ä½¿ç”¨å‘é‡ç›¸ä¼¼åº¦
        keywords = set(query.lower().split())

        scored_memories = []
        for mem in self.memories:
            score = 0
            mem_words = set(mem.content.lower().split())
            score += len(keywords & mem_words)
            score += mem.importance * 0.1
            score -= (time.time() - mem.timestamp) / 86400 * 0.01  # æ—¶é—´è¡°å‡

            scored_memories.append((mem, score))

        scored_memories.sort(key=lambda x: x[1], reverse=True)
        return [m for m, s in scored_memories[:k]]

    def get_recent(self, n: int = 10, memory_type: str = None) -> List[Memory]:
        """è·å–æœ€è¿‘çš„è®°å¿†"""
        if memory_type:
            indices = self._memory_index.get(memory_type, [])
            memories = [self.memories[i] for i in indices]
        else:
            memories = self.memories

        return sorted(memories, key=lambda x: x.timestamp, reverse=True)[:n]

    def summarize(self) -> str:
        """æ€»ç»“è®°å¿†"""
        recent = self.get_recent(20)
        observations = [m.content for m in recent if m.memory_type == "observation"]
        actions = [m.content for m in recent if m.memory_type == "action"]

        summary = f"æœ€è¿‘è§‚å¯Ÿ:\n" + "\n".join(f"- {o}" for o in observations[:5])
        summary += f"\n\næœ€è¿‘è¡ŒåŠ¨:\n" + "\n".join(f"- {a}" for a in actions[:5])

        return summary


class AIAgent:
    """
    AI Agent

    å®‡å®™ç¬¬ä¸€çš„è‡ªä¸»AIä»£ç†
    """

    def __init__(self, name: str = "GodHand Agent", llm_client=None):
        self.name = name
        self.llm = llm_client
        self.state = AgentState.IDLE

        # è®°å¿†ç³»ç»Ÿ
        self.memory = LongTermMemory()
        self.working_memory: Dict[str, Any] = {}  # å·¥ä½œè®°å¿†

        # ç›®æ ‡ç®¡ç†
        self.goals: List[Goal] = []
        self.current_goal: Optional[Goal] = None

        # æ‰§è¡Œå†å²
        self.action_history: List[Dict] = []

        # æŠ€èƒ½æ³¨å†Œ
        self.skills: Dict[str, Callable] = {}

        # åæ€è®¡æ•°
        self.action_count_since_reflection = 0
        self.reflection_interval = 5

        print(f"ğŸ¤– [AIAgent] {name} åˆå§‹åŒ–å®Œæˆ")

    def register_skill(self, name: str, func: Callable):
        """æ³¨å†ŒæŠ€èƒ½"""
        self.skills[name] = func
        print(f"âœ… æŠ€èƒ½å·²æ³¨å†Œ: {name}")

    def perceive(self, observation: str, importance: float = 1.0):
        """æ„ŸçŸ¥ç¯å¢ƒ"""
        memory = Memory(
            content=observation,
            memory_type="observation",
            timestamp=time.time(),
            importance=importance
        )
        self.memory.add(memory)
        print(f"ğŸ‘ï¸  [æ„ŸçŸ¥] {observation[:100]}...")

    def set_goal(self, description: str, priority: TaskPriority = TaskPriority.MEDIUM) -> Goal:
        """è®¾ç½®ç›®æ ‡"""
        goal_id = hashlib.md5(f"{description}{time.time()}".encode()).hexdigest()[:8]

        goal = Goal(
            id=goal_id,
            description=description,
            priority=priority
        )

        self.goals.append(goal)
        self.goals.sort(key=lambda g: g.priority.value, reverse=True)

        # è®°å½•åˆ°è®°å¿†
        self.memory.add(Memory(
            content=f"è®¾å®šç›®æ ‡: {description}",
            memory_type="plan",
            timestamp=time.time(),
            importance=priority.value
        ))

        print(f"ğŸ¯ [ç›®æ ‡] {description} (ä¼˜å…ˆçº§: {priority.name})")
        return goal

    def plan(self, goal: Goal = None) -> List[Dict]:
        """åˆ¶å®šè®¡åˆ’"""
        self.state = AgentState.PLANNING

        target = goal or self.current_goal
        if not target:
            return []

        # è·å–ç›¸å…³è®°å¿†
        relevant_memories = self.memory.retrieve(target.description, k=10)
        memory_context = "\n".join([m.content for m in relevant_memories])

        # ä½¿ç”¨LLMåˆ¶å®šè®¡åˆ’ï¼ˆå¦‚æœæœ‰ï¼‰
        if self.llm:
            plan = self._plan_with_llm(target, memory_context)
        else:
            plan = self._plan_with_rules(target)

        # è®°å½•è®¡åˆ’
        self.memory.add(Memory(
            content=f"åˆ¶å®šè®¡åˆ’: {len(plan)} ä¸ªæ­¥éª¤",
            memory_type="plan",
            timestamp=time.time(),
            importance=target.priority.value
        ))

        self.state = AgentState.IDLE
        return plan

    def _plan_with_llm(self, goal: Goal, context: str) -> List[Dict]:
        """ä½¿ç”¨LLMåˆ¶å®šè®¡åˆ’"""
        # è¿™é‡Œåº”è¯¥è°ƒç”¨LLM API
        # ç®€åŒ–å®ç°
        return [
            {"step": 1, "action": "analyze", "description": f"åˆ†æç›®æ ‡: {goal.description}"},
            {"step": 2, "action": "execute", "description": "æ‰§è¡Œä¸»è¦ä»»åŠ¡"},
            {"step": 3, "action": "verify", "description": "éªŒè¯ç»“æœ"}
        ]

    def _plan_with_rules(self, goal: Goal) -> List[Dict]:
        """ä½¿ç”¨è§„åˆ™åˆ¶å®šè®¡åˆ’"""
        description = goal.description.lower()

        if "æ‰“å¼€" in description:
            app = description.replace("æ‰“å¼€", "").strip()
            return [
                {"step": 1, "action": "open_app", "target": app},
                {"step": 2, "action": "wait", "duration": 2},
                {"step": 3, "action": "verify", "description": f"ç¡®è®¤ {app} å·²æ‰“å¼€"}
            ]

        return [
            {"step": 1, "action": "analyze", "description": "åˆ†æä»»åŠ¡"},
            {"step": 2, "action": "execute", "description": "æ‰§è¡Œä»»åŠ¡"}
        ]

    def execute(self, action: Dict) -> Dict:
        """æ‰§è¡ŒåŠ¨ä½œ"""
        self.state = AgentState.EXECUTING

        action_type = action.get("action", "unknown")
        print(f"âš¡ [æ‰§è¡Œ] {action_type}: {action.get('description', '')}")

        result = {"success": False, "output": ""}

        # æ‰§è¡ŒæŠ€èƒ½
        if action_type in self.skills:
            try:
                skill_func = self.skills[action_type]
                result = skill_func(**{k: v for k, v in action.items() if k != "action"})
                result["success"] = True
            except Exception as e:
                result["error"] = str(e)
        else:
            result["output"] = f"æœªçŸ¥åŠ¨ä½œ: {action_type}"

        # è®°å½•è¡ŒåŠ¨
        self.action_history.append({
            "action": action,
            "result": result,
            "timestamp": time.time()
        })

        self.memory.add(Memory(
            content=f"æ‰§è¡Œ: {action_type} - ç»“æœ: {result.get('output', '')[:100]}",
            memory_type="action",
            timestamp=time.time(),
            importance=2.0 if result["success"] else 3.0
        ))

        self.action_count_since_reflection += 1

        # è§¦å‘åæ€
        if self.action_count_since_reflection >= self.reflection_interval:
            self.reflect()

        self.state = AgentState.IDLE
        return result

    def reflect(self):
        """åæ€"""
        self.state = AgentState.REFLECTING
        print("ğŸ¤” [åæ€] åˆ†ææœ€è¿‘çš„è¡¨ç°...")

        # è·å–æœ€è¿‘çš„è¡ŒåŠ¨
        recent_actions = self.action_history[-self.reflection_interval:]

        successes = sum(1 for a in recent_actions if a["result"].get("success"))
        failures = len(recent_actions) - successes

        reflection_content = f"æœ€è¿‘ {len(recent_actions)} ä¸ªè¡ŒåŠ¨: "
        reflection_content += f"æˆåŠŸ {successes} æ¬¡, å¤±è´¥ {failures} æ¬¡"

        if failures > 0:
            reflection_content += ". éœ€è¦æ”¹è¿›ç­–ç•¥ã€‚"
        else:
            reflection_content += ". è¡¨ç°è‰¯å¥½ã€‚"

        self.memory.add(Memory(
            content=reflection_content,
            memory_type="reflection",
            timestamp=time.time(),
            importance=2.5
        ))

        print(f"ğŸ’­ {reflection_content}")

        self.action_count_since_reflection = 0
        self.state = AgentState.IDLE

    def run(self, instruction: str) -> Dict:
        """è¿è¡Œå®Œæ•´å¾ªç¯"""
        print(f"\n{'='*60}")
        print(f"ğŸš€ [è¿è¡Œ] {instruction}")
        print('='*60)

        # 1. æ„ŸçŸ¥
        self.perceive(f"æ”¶åˆ°æŒ‡ä»¤: {instruction}", importance=2.0)

        # 2. è®¾å®šç›®æ ‡
        goal = self.set_goal(instruction, TaskPriority.HIGH)
        self.current_goal = goal

        # 3. åˆ¶å®šè®¡åˆ’
        plan = self.plan(goal)
        print(f"\nğŸ“‹ è®¡åˆ’: {len(plan)} ä¸ªæ­¥éª¤")

        # 4. æ‰§è¡Œ
        results = []
        for step in plan:
            result = self.execute(step)
            results.append(result)

            if not result.get("success"):
                print(f"âŒ æ­¥éª¤å¤±è´¥: {step}")
                # å¯ä»¥å°è¯•æ¢å¤æˆ–é‡è§„åˆ’

        # 5. æ€»ç»“
        success_count = sum(1 for r in results if r.get("success"))
        print(f"\nâœ… å®Œæˆ: {success_count}/{len(results)} ä¸ªæ­¥éª¤æˆåŠŸ")

        return {
            "goal": goal.description,
            "plan": plan,
            "results": results,
            "success_rate": success_count / len(results) if results else 0
        }

    def chat(self, message: str) -> str:
        """å¯¹è¯æ¨¡å¼"""
        # æ£€ç´¢ç›¸å…³è®°å¿†
        relevant = self.memory.retrieve(message, k=5)
        context = self.memory.summarize()

        # è¿™é‡Œåº”è¯¥ä½¿ç”¨LLMç”Ÿæˆå›å¤
        response = f"æˆ‘ç†è§£äº†: {message}\n"
        response += f"æ ¹æ®æˆ‘çš„è®°å¿†ï¼Œ{context[:200]}..."

        # è®°å½•å¯¹è¯
        self.memory.add(Memory(
            content=f"ç”¨æˆ·: {message}",
            memory_type="observation",
            timestamp=time.time()
        ))
        self.memory.add(Memory(
            content=f"åŠ©æ‰‹: {response[:100]}",
            memory_type="action",
            timestamp=time.time()
        ))

        return response

    def get_status(self) -> Dict:
        """è·å–çŠ¶æ€"""
        return {
            "name": self.name,
            "state": self.state.value,
            "memory_count": len(self.memory.memories),
            "goals_count": len(self.goals),
            "skills_count": len(self.skills),
            "action_history_count": len(self.action_history)
        }


# ä¾¿æ·å‡½æ•°
def create_agent(name: str = "Agent", llm_client=None) -> AIAgent:
    """åˆ›å»ºAI Agent"""
    return AIAgent(name, llm_client)


if __name__ == "__main__":
    # æµ‹è¯•
    agent = AIAgent("Test Agent")

    # æ³¨å†Œä¸€äº›æµ‹è¯•æŠ€èƒ½
    agent.register_skill("open_app", lambda target: {"output": f"æ‰“å¼€ {target}"})
    agent.register_skill("wait", lambda duration: {"output": f"ç­‰å¾… {duration} ç§’"})
    agent.register_skill("analyze", lambda **kwargs: {"output": "åˆ†æå®Œæˆ"})
    agent.register_skill("verify", lambda **kwargs: {"output": "éªŒè¯é€šè¿‡"})

    # è¿è¡Œæµ‹è¯•
    result = agent.run("æ‰“å¼€è®¡ç®—å™¨")
    print(f"\nç»“æœ: {result}")

    # æŸ¥çœ‹çŠ¶æ€
    print(f"\nçŠ¶æ€: {agent.get_status()}")
